#include <ros/ros.h>
#include <ros/package.h>

#include <sensor_msgs/PointCloud2.h>
#include <sensor_msgs/Image.h>
#include <sensor_msgs/image_encodings.h>
#include "std_msgs/String.h"
#include "std_msgs/UInt32.h"
#include <cv_bridge/cv_bridge.h>
//#include <bender_srvs/ImageDetection.h>
#include "opt_msgs/DetectionArray.h"
#include "opt_msgs/Detection.h"
#include "opt_msgs/TrackArray.h"
#include "opt_msgs/Track.h"
#include "open_ptrack/opt_utils/conversions.h"

//Opencv
//#include "cv.h"
//#include "highgui.h"
//#include <ml.h>	
#include <opencv2/highgui/highgui.hpp>
#include <opencv2/ml/ml.hpp>
#include <opencv2/core/core.hpp>

//C++
#include <iostream>
#include <math.h>
#include <algorithm>
#include <fstream>
#include <sstream>
#include <string.h>
#include <vector>
#include <cstdlib>
#include <unistd.h>
#include <boost/filesystem.hpp>
#include <valarray>

//Time Synchronizer
// NOTE: Time Synchronizer conflicts with QT includes may need to investigate
#include <message_filters/subscriber.h>
#include <message_filters/synchronizer.h>
#include <message_filters/sync_policies/approximate_time.h>

#include "open_ptrack/detection/detection.h"
#include "open_ptrack/opt_follow/FeatureExtractor.h"

using namespace cv;
using namespace std;


ros::Publisher pub;
ros::Publisher pub_str;
bool init_done_flag_ = false;
int target_id_ = -1;

FeatureExtractor feat_ext = FeatureExtractor();
vector<Histogram> prev_hist_features_target_;
vector<Histogram> hist_features_target_;
vector< vector<Histogram> > hist_distractors_;
const int max_distractors_ = 10;
int idx_pop_distractor_ = 0;

bool set_camera_parameters_ = false;
open_ptrack::opt_utils::Conversions converter_;
Eigen::Matrix3f intrinsic_matrix_;
int height_;
int width_;

bool flag_perdido_recien = false;
double target_dist_ref_ = 0.15;

cv::Mat convertROSImageToCV(const sensor_msgs::ImageConstPtr &image)
{
	cv_bridge::CvImagePtr cv_ptr;
	try
	{	
		cv_ptr = cv_bridge::toCvCopy(image, image->encoding);
	}
	catch (cv_bridge::Exception &e)
	{
		ROS_ERROR("cv_bridge exception: %s", e.what());
	}

	return cv::Mat(cv_ptr->image);
}


void convertCVToROSImage(cv::Mat input, sensor_msgs::Image &output, std::string encoding)
{
	cv_bridge::CvImage cv_i;
	cv_i.header.stamp = ros::Time::now();
	cv_i.header.frame_id = "image";
	cv_i.encoding = encoding; //sensor_msgs::image_encodings::MONO8; BGR8;
	cv_i.image = input;

	sensor_msgs::Image im;
	cv_i.toImageMsg(im);
	output = im;
}


int isIndexInTracks(opt_msgs::TrackArray &tracks_msg, int id)
{

	for (int i = 0; i < tracks_msg.tracks.size(); i++)
	{
		if (tracks_msg.tracks[i].id == id)
			return i;
	}
	
	return -1;
}


void printHistograms(vector<Histogram> &hists)
{
	cout << "Histogramas: " << endl;

	for (int i = 0; i < hists.size(); i++)
	{
		Histogram hist = hists.at(i);

		cout << "Histograma nro " << i << ": " << endl;
		cout << "Size: " << hist.size() << endl;
		for (int j = 0; j < hist.size(); j++)
		{
			cout << hist[j] << ", ";
		}
		cout << endl;
	}
}


void getBbox(opt_msgs::Track &msg_track, Rect &rect)
{
	//Rect rect;
	//cout << "antes  ";
	/*rect.x = (int) (msg_track.box_2D.x + 0.2*msg_track.box_2D.width);
	rect.y = (int) (msg_track.box_2D.y + 0.01*msg_track.box_2D.height);
	rect.width = (int) (0.6*msg_track.box_2D.width);
	rect.height = (int) (0.4*msg_track.box_2D.height);*/

	//cout << "rect " << rect << endl;
	/*rect.x = msg_track.box_2D.x + 0.125*msg_track.box_2D.width;
	rect.y = msg_track.box_2D.y - 0.02*msg_track.box_2D.height;
	rect.width = 0.75*msg_track.box_2D.width;
	rect.height = 0.55*msg_track.box_2D.height;*/

	/*rect.x = msg_track.box_2D.x;
	rect.y = msg_track.box_2D.y;
	rect.width = msg_track.box_2D.width;
	rect.height = msg_track.box_2D.height;*/

	rect.x = msg_track.box_2D.x + 0.125*msg_track.box_2D.width;
	rect.y = msg_track.box_2D.y - 0.02*msg_track.box_2D.height;
	rect.width = 0.75*msg_track.box_2D.width;
	rect.height = 0.5*msg_track.box_2D.height;

	//cout << "rect gb: " << rect << endl;
	//return rect;
}


// Recorta imagen
cv::Mat cropImage(cv::Mat &image, Rect &rect)
{
	int x2 = min(rect.x+rect.width, image.cols);
	int y2 = min(rect.y+rect.height, image.rows);
	rect.x = max(rect.x, 0);
	rect.y = max(rect.y, 0);
	rect.width = x2 - rect.x;
	rect.height = y2 - rect.y;

	if (rect.y+rect.height >= image.rows)
		rect.height = image.rows - rect.y - 1;
	if (rect.x+rect.width >= image.cols)
		rect.width = image.cols - rect.x -1;

	cv::Mat rtn = image(rect).clone();

	return rtn;

	/*
	int x2 = min(rect.x+rect.width, image.cols);
	int y2 = min(rect.y+rect.height, image.rows);
	rect.x = max(rect.x, 0);
	rect.y = max(rect.y, 0);
	rect.width = x2 - rect.x;
	rect.height = y2 - rect.y;


	if (rect.x > 459)
		rect.x = 440;
	if (rect.width < 0)
		rect.width = 0;
	if (rect.height < 0)
		rect.height = 0;

	cv::Mat rtn = image(rect).clone();


	return rtn;
	*/
}


bool overlaps(cv::Rect &r1, cv::Rect &r2)
{
	Rect r3 = r1 & r2; //interseccion
	return ((r3.area()) > 0);
}

double interOverUnion(cv::Rect &r1, cv::Rect &r2)
{
	Rect r_union = r1 | r2;
	Rect r_inter = r1 & r2;

	if (r_union.area() == 0)
		return 0.0;

	double rtn = (1.0 * r_inter.area() ) / r_union.area();
	return rtn;
}


//Distractor list
bool updateDistractorList(cv::Mat &img, opt_msgs::TrackArray &tracks_msg, opt_msgs::Track &track_target)
{
	Rect rect_target;
	getBbox(track_target, rect_target);
	cv::Mat img_target = cropImage(img, rect_target);
	cout << " 4.1" << endl;

	bool found_target = false;
	bool update_prev = false;
	vector<Histogram> hist_features_target;

	if (track_target.visibility == opt_msgs::Track::VISIBLE)
	{
		feat_ext.getFeatures(img_target, hist_features_target);
		cout << " 5.1" << endl;

		double dist_between_target = feat_ext.compareArrayHist(prev_hist_features_target_, hist_features_target);

		if (dist_between_target < 0.4)
		{
			found_target = true;
			hist_features_target_ = hist_features_target;

			if (dist_between_target < 0.2)
			{
				update_prev = true;
			}
		}
		// Considerar threshold dist < 0.4 como si fuera una deteccion,
		// comparando con _prev_hist 
		// En caso contrario, exigir a los distractores tener un dist > 0.5
		// y no se debe actualizar _prev_hist ni _hist_features
	}

	for (int i = 0; i < tracks_msg.tracks.size(); i++)
	{
		opt_msgs::Track msg_track = tracks_msg.tracks[i];

		Rect rect_track;
		getBbox(msg_track, rect_track);

		if (overlaps(rect_target, rect_track))
			continue;

		vector<Histogram> hist_distractor;
		cv::Mat blob_im = cropImage(img,rect_track);
		cout << " 4.0 ";
		feat_ext.getFeatures(blob_im, hist_distractor);
		cout << " 5" << endl;

		// Si no se encontro el target, la distancia debe ser > 0.5
		if (!found_target)
		{
			double dist = feat_ext.compareArrayHist(prev_hist_features_target_, hist_distractor);
			if (dist < 0.5)
				continue;
		}

		if (hist_distractors_.size() < max_distractors_)
		{
			hist_distractors_.push_back(hist_distractor);
		}
		else
		{
			hist_distractors_.at(idx_pop_distractor_) = hist_distractor;
			idx_pop_distractor_ = (idx_pop_distractor_ + 1) % max_distractors_;
		}
	}

	return update_prev;
}



//Distractor list
void updateDistractorList(cv::Mat &img, vector<Rect> &r_detections, Rect &r_target)
{
	cv::Mat img_target = cropImage(img, r_target);

	vector<Histogram> hist_features_target;
	feat_ext.getFeatures(img_target, hist_features_target);

	double dist_between_target = feat_ext.compareArrayHist(prev_hist_features_target_, hist_features_target);
	cout << "Distancia entre target previo: " << dist_between_target << endl;

	if (dist_between_target > 0 && dist_between_target < 0.05)
	{
		target_dist_ref_ = 0.1;
	}
	else
	{
		target_dist_ref_ = 0.2;
	}

	prev_hist_features_target_ = hist_features_target_;
	hist_features_target_ = hist_features_target;

	for (int i = 0; i < r_detections.size(); i++)
	{
		Rect rect_detection = r_detections.at(i);

		if (overlaps(r_target, rect_detection))
			continue;

		vector<Histogram> hist_distractor;
		cv::Mat blob_im = cropImage(img,rect_detection);
		
		if (blob_im.cols < 70 || blob_im.rows < 100)
			continue;

		cv::imshow("hola", blob_im);
		cv::waitKey(30);

		feat_ext.getFeatures(blob_im, hist_distractor);
		
		if (hist_distractors_.size() < max_distractors_)
		{
			hist_distractors_.push_back(hist_distractor);
		}
		else
		{
			hist_distractors_.at(idx_pop_distractor_) = hist_distractor;
			idx_pop_distractor_ = (idx_pop_distractor_ + 1) % max_distractors_;
		}

		cout << "Distancia entre diferentes   : " << feat_ext.compareArrayHist(hist_features_target, hist_distractor) << endl;
	}
}



void updateFeatureWeights(bool update_prev)
{
	for (int i = 0; i < feat_ext.getNroFeatures(); i++)
	{
		Histogram prev_hist, last_hist;
		prev_hist = prev_hist_features_target_.at(i);
		last_hist = hist_features_target_.at(i);

		double last_target_dist = feat_ext.d_bhattacharyya(prev_hist, last_hist);

		double average_dist = 0;
		for (int j = 0; j < hist_distractors_.size(); j++)
		{
			Histogram distractor_hist = hist_distractors_.at(j).at(i);
			average_dist += feat_ext.d_bhattacharyya(last_hist, distractor_hist);
		}

		if (hist_distractors_.size() > 0)
			average_dist = average_dist / hist_distractors_.size();
		else
			average_dist = 0;

		double score_i = average_dist - last_target_dist;
		feat_ext.updateWeight(i, score_i);
	}

	feat_ext.normalizeWeights();

	if (update_prev)
	{
		prev_hist_features_target_ = hist_features_target_;
	}
}



void updateFeatureWeights()
{
	for (int i = 0; i < feat_ext.getNroFeatures(); i++)
	{
		Histogram prev_hist, last_hist;
		prev_hist = prev_hist_features_target_.at(i);
		last_hist = hist_features_target_.at(i);

		double last_target_dist = feat_ext.d_bhattacharyya(prev_hist, last_hist);

		double average_dist = 0;
		for (int j = 0; j < hist_distractors_.size(); j++)
		{
			Histogram distractor_hist = hist_distractors_.at(j).at(i);
			average_dist += feat_ext.d_bhattacharyya(last_hist, distractor_hist);
		}

		if (hist_distractors_.size() > 0)
			average_dist = average_dist / hist_distractors_.size();
		else
			average_dist = 0;

		double score_i = average_dist - last_target_dist;
		//cout << "score " << i << ": " << score_i << endl;
		feat_ext.updateWeight(i, score_i);
	}

	feat_ext.normalizeWeights();

}


void callback(const sensor_msgs::ImageConstPtr &image_msg, const opt_msgs::TrackArray::ConstPtr &tracks_msg)
{
	Mat image = convertROSImageToCV(image_msg);
	opt_msgs::Track track_target_msg;
	
	double distance_thr = 1.8;

	//Inicializacion. Determina el target a seguir
	if (!init_done_flag_)
	{
		for (int i = 0; i < tracks_msg->tracks.size(); i++)
		{
			opt_msgs::Track msg_track = tracks_msg->tracks[i];
			if (msg_track.distance < distance_thr) //se define por una distancia minima
			{
				//TODO: detectar cara
				//TODO: almacenar informacion (crear clase Target)
				target_id_ = msg_track.id;
				cout << "Target encontrado: " << target_id_ << endl;

				Rect rect;
				getBbox(msg_track, rect);
				cv::Mat blob_im = cropImage(image, rect);
				cout << " 4.3" ;
				feat_ext.getFeatures(blob_im, prev_hist_features_target_);
				cout << " 5.3" << endl;

				init_done_flag_ = true;
			}
		}
	}

	else // !init_done_flag
	{cout << "iniciado" << endl;
		opt_msgs::TrackArray track_array = *tracks_msg;
		int idx = isIndexInTracks(track_array, target_id_);

		if (idx >= 0) //Si no se ha perdido el track
		{
			opt_msgs::Track msg_track_target = track_array.tracks[idx];

			cout << "por update distractor ";
			bool update_prev = updateDistractorList(image, track_array, msg_track_target);
			updateFeatureWeights(update_prev);
			cout << "pesos actualizados" << endl;
			//feat_ext.printWeights();

			Rect rect;
			getBbox(msg_track_target, rect);
			cout << "predibujo ";
			cv::rectangle(image, rect, Scalar(0,255,0));
			cout << "dibujo rect " << endl;

		}
		else //Se perdio el track, hay que encontrar al target dentro de las demas detecciones
		{
			cout << "Target perdido" << endl;

			double min_dist = 100;
			int idx_dist;
			vector<Histogram> hist_target;

			for (int i = 0; i < tracks_msg->tracks.size(); i++)
			{
				opt_msgs::Track msg_track = track_array.tracks[i];//tracks_msg->tracks[i];
				Rect rect;
				getBbox(msg_track, rect);
				cout << "44 ";
				cv::Mat blob_im = cropImage(image, rect);
				cout << " 4.4";
				vector<Histogram> hist_features;
				feat_ext.getFeatures(blob_im, hist_features);
				cout << " 5.4" << endl;
				
				double dist = feat_ext.compareArrayHist(prev_hist_features_target_, hist_features);

				if (dist < min_dist)
				{
					min_dist = dist;
					idx_dist = i;
					hist_target = hist_features;
				}
			}

			if (min_dist < 0.2)
			{
				target_id_ = tracks_msg->tracks[idx_dist].id;
				prev_hist_features_target_ = hist_target;
				cout << "Encontrado " << min_dist << endl;
			}

		}

		sensor_msgs::Image im;
		convertCVToROSImage(image, im, sensor_msgs::image_encodings::BGR8);
		//pub.publish(track_target_msg);

		cv::imshow("hola", image);
		cv::waitKey(30);
	}

	pub.publish(track_target_msg);
	
}


void callbackNoFeat(const sensor_msgs::ImageConstPtr &image_msg, const opt_msgs::TrackArray::ConstPtr &tracks_msg)
{
	Mat image = convertROSImageToCV(image_msg);
	opt_msgs::Track track_target_msg;
	
	double distance_thr = 1.8;

	//Inicializacion. Determina el target a seguir

	//Test
	cout << "Callback" << endl;
	for (int i = 0; i < tracks_msg->tracks.size(); i++)
	{
		opt_msgs::Track msg_track = tracks_msg->tracks[i];
		Rect rect;
		getBbox(msg_track, rect);
		cv::rectangle(image, rect, Scalar(0,0,255));
	}
	cv::imshow("Following", image);
	cv::waitKey(30);
	return;
	//endTest


	if (!init_done_flag_)
	{
		for (int i = 0; i < tracks_msg->tracks.size(); i++)
		{
			opt_msgs::Track msg_track = tracks_msg->tracks[i];
			if (msg_track.distance < distance_thr && msg_track.confidence > 1) //se define por una distancia minima
			{
				//TODO: detectar cara
				//TODO: almacenar informacion (crear clase Target)
				target_id_ = msg_track.id;
				track_target_msg = msg_track;

				cout << "Target encontrado: " << target_id_ << endl;

				Rect rect;
				getBbox(msg_track, rect);

				init_done_flag_ = true;
			}
		}
	}

	else // !init_done_flag
	{
		opt_msgs::TrackArray track_array = *tracks_msg;
		int idx = isIndexInTracks(track_array, target_id_);

		if (idx >= 0) //Si no se ha perdido el track
		{
			track_target_msg = track_array.tracks[idx];
			opt_msgs::Track msg_track_target = track_array.tracks[idx];
			cout << "Target es: " << track_array.tracks[idx].id << endl;

			Rect rect;
			getBbox(msg_track_target, rect);
			//cout << "BBox: " << rect << endl;

			cv::rectangle(image, rect, Scalar(255,255,0));

		}
		else //Se perdio el track, hay que encontrar al target dentro de las demas detecciones
		{
			cout << "Target perdido" << endl;
			init_done_flag_ = false;
			/*
			for (int i = 0; i < tracks_msg->tracks.size(); i++)
			{
				opt_msgs::Track msg_track = track_array.tracks[i];//tracks_msg->tracks[i];
				Rect rect;
				getBbox(msg_track, rect);

			}

			if (false)
			{
				target_id_ = tracks_msg->tracks[idx_dist].id;
				cout << "Encontrado " << min_dist << endl;
			}
			*/

		}

		cv::imshow("Following", image);

		sensor_msgs::Image im;
		convertCVToROSImage(image, im, sensor_msgs::image_encodings::BGR8);
		//pub.publish(track_target_msg);

		
		cv::waitKey(30);
	}

	pub.publish(track_target_msg);
	
}


void getRect(opt_msgs::Detection &detection, cv::Rect &rect)
{

	Eigen::Vector3f centroid3d(detection.centroid.x, detection.centroid.y, detection.centroid.z);
    Eigen::Vector3f centroid2d = converter_.world2cam(centroid3d, intrinsic_matrix_);

    // theoretical person top point:
    Eigen::Vector3f top3d(detection.top.x, detection.top.y, detection.top.z);
    Eigen::Vector3f top2d = converter_.world2cam(top3d, intrinsic_matrix_);

    // Define Rect and make sure it is not out of the image:
    int h = centroid2d(1) - top2d(1);
    int w = h * 2 / 3.0;
    int x = std::max(0, int(centroid2d(0) - w / 2.0));
    int y = std::max(0, int(top2d(1)));
    h = std::min(int(height_ - y), int(h));
    w = std::min(int(width_ - x), int(w));

    rect.x = x;
    rect.y = y;
    rect.width = w;
    rect.height = h;
}


bool findTargetRect(cv::Mat &image, opt_msgs::TrackArray &tracks_msg, opt_msgs::DetectionArray &detections_msg, Rect &r_target, vector<Rect> &rects)
{
	int idx = isIndexInTracks(tracks_msg, target_id_);
	if (idx < 0)
		return false;

	// Buscar solamente si el track es valido y confiable
	opt_msgs::Track track = tracks_msg.tracks[idx];
	int matchs;
	int detection_idx;
	if (track.confidence > 1 && track.visibility == opt_msgs::Track::VISIBLE)
	{
		Rect r_track;
		getBbox(track, r_track);
		//cv::rectangle(image, r_track, Scalar(0,255,255));

		matchs = 0;
		for (int i = 0; i < detections_msg.detections.size(); i++)
		{
			opt_msgs::Detection detection = detections_msg.detections[i];
			Rect r_detection;
			getRect(detection, r_detection);
			cv::rectangle(image, r_detection, Scalar(0,255,0));

			if (interOverUnion(r_track, r_detection) > 0.6)
			{
				detection_idx = i;
				matchs++;
			}
		}
	}
	else
	{
		return false;	
	}

	if (matchs == 1)
	{
		rects.clear();
		for (int i = 0; i < detections_msg.detections.size(); i++)
		{
			opt_msgs::Detection detection = detections_msg.detections[i];
			Rect r_detection;
			getRect(detection, r_detection);

			if (detection_idx == i)
			{
				r_target = r_detection;
				cv::rectangle(image, r_target, Scalar(0,0,255));
			}
			else
			{
				rects.push_back(r_detection);
				cv::rectangle(image, r_detection, Scalar(255,0,0));
			}
		}

		return true;
	}

	return false;
}


bool findTrackRect(opt_msgs::Track &track, opt_msgs::DetectionArray &detections_msg, Rect &rect_track)
{
	Rect r_track;
	getBbox(track, r_track);

	int track_idx;
	int matchs = 0;
	for (int i = 0; i < detections_msg.detections.size(); i++)
	{
		opt_msgs::Detection detection = detections_msg.detections[i];
		Rect r_detection;
		getRect(detection, r_detection);

		if (interOverUnion(r_track, r_detection) > 0.5)
		{
			rect_track = r_detection;
			track_idx = i;
			matchs++;
		}
		//cout << "interOVerUnion: " << interOverUnion(r_track, r_detection) << endl;
	}

	if (matchs == 1)
	{
		return true;
	}

	return false;
}


void callbackNoFeatCarac(const sensor_msgs::ImageConstPtr &image_msg, const opt_msgs::TrackArray::ConstPtr &tracks_msg, const opt_msgs::DetectionArray::ConstPtr &detections_msg)
{
	Mat image = convertROSImageToCV(image_msg);

	if (!set_camera_parameters_)
	{
		intrinsic_matrix_;
		for(int i = 0; i < 3; i++)
			for(int j = 0; j < 3; j++)
				intrinsic_matrix_(i, j) = detections_msg->intrinsic_matrix[i * 3 + j];
		
		height_ = image.rows;
		width_ = image.cols;
		set_camera_parameters_ = true;
	}

	double distance_thr = 2.5;
	if (!init_done_flag_)
	{
		ROS_INFO("Buscando target");
		for (int i = 0; i < tracks_msg->tracks.size(); i++)
		{
			opt_msgs::Track msg_track = tracks_msg->tracks[i];
			cout << "distancia: " << msg_track.distance << " confidencia: " << msg_track.confidence << endl;
			if (msg_track.distance < distance_thr && msg_track.confidence > 0.8) //se define por una distancia minima
			{
				//TODO: detectar cara
				//TODO: almacenar informacion (crear clase Target)
				

				//cout << "Target encontrado: " << target_id_ << endl;

				//init_done_flag_ = true;

				Rect rect_target;
				opt_msgs::DetectionArray det_arr = *detections_msg;

				Rect r_aux;
				getBbox(msg_track, r_aux);
				cv::rectangle(image, r_aux, Scalar(255,255,0));

				cout << "Rect: " << r_aux << endl;

				if (findTrackRect(msg_track, det_arr, rect_target))
				{
					target_id_ = msg_track.id;

					cout << "Target encontrado: " << target_id_ << endl;

					cv::Mat blob_im = cropImage(image,rect_target);

					feat_ext.getFeatures(blob_im, hist_features_target_);
					init_done_flag_ = true;
					break;
				}
			}
		}
	}
	else // !init_done_flag
	{
		opt_msgs::TrackArray track_array = *tracks_msg;
		opt_msgs::DetectionArray detection_array = *detections_msg;

		int idx = isIndexInTracks(track_array, target_id_);
		if (idx >= 0) //Si no se ha perdido el track
		{
			Rect r_target;
			vector<Rect> rects;

			if (findTargetRect(image, track_array, detection_array, r_target, rects))
			{   
				updateDistractorList(image, rects, r_target);
				updateFeatureWeights();

				//feat_ext.printWeights();
				//TODO: actualizar distractor list -> requiere los rectangulos y las imagenes
				//TODO: actualizar pesos -> requiere la distractor list

				cv::rectangle(image, r_target, Scalar(0,0,255));//Dibujar target
				for (int i = 0; i < rects.size(); i++)//Dibujar los tracks que no son target
				{
					cv::rectangle(image, rects.at(i), Scalar(255,0,0));
				}
			}
			else//Dibujar el track del target
			{
				opt_msgs::Track track = track_array.tracks[idx];
				Rect r_track;
				getBbox(track, r_track);
				cv::rectangle(image, r_track, Scalar(255,255,255));
			}
		}
		else //Se perdio el track, hay que encontrar al target dentro de las demas detecciones
		{
			if (!flag_perdido_recien)
			{
				cout << "Target perdido" << endl;
				flag_perdido_recien = true;
			}
				

			for (int i = 0; i < tracks_msg->tracks.size(); i++)
			{
				opt_msgs::Track msg_track = tracks_msg->tracks[i];
				opt_msgs::DetectionArray det_arr = *detections_msg;
				Rect rect_target;
				if (findTrackRect(msg_track, det_arr, rect_target))
				{
					cv::Mat blob_im = cropImage(image,rect_target);
					vector<Histogram> hist_track;
					feat_ext.getFeatures(blob_im, hist_track);

					double dist_target_track1 = feat_ext.compareArrayHist(hist_features_target_, hist_track);
					double dist_target_track2 = feat_ext.compareArrayHist(prev_hist_features_target_, hist_track);
					cout << "Dist: " << dist_target_track1 << "\t";
					if (abs(dist_target_track1) < target_dist_ref_ || abs(dist_target_track2) < target_dist_ref_)
					{
						target_id_ = msg_track.id;
						prev_hist_features_target_ = hist_features_target_;
						hist_features_target_ = hist_track;
						flag_perdido_recien = false;

						feat_ext.printWeights();

						cv::imshow("Reencontrado", blob_im);

						cout << "\nTarget re-encontrado en ID: " << target_id_ << endl;
						break;
					}
					
				}
			}
			//TODO: comparar modelo con los demas tracks. Se debe utilizar el blob de detector/detections
			//TODO: Hacer for en todos los tracks y utilizar funcion findTrackRect, que deberia entregar el rect correspondiente a detector/detections
			//TODO: Para cada rect, extraer caracteristicas y comprar con modelo de target. Si hay suerte, encontrará al target.

			
			//init_done_flag_ = false;

		}
	}

	cv::imshow("Following", image);		
	cv::waitKey(30);

	std_msgs::String msg;
	msg.data = "hola";
	pub_str.publish(msg);
}


int main(int argc, char **argv)
{
	ros::init(argc, argv, "following");

	ros::NodeHandle n;

	//cv::namedWindow("Following");

	message_filters::Subscriber<sensor_msgs::Image> sub_image_(n, "/HaarDispAdaColorImage", 1);
	message_filters::Subscriber<opt_msgs::TrackArray> sub_tracks_(n, "/tracker/tracks_smoothed", 1);

	typedef message_filters::sync_policies::ApproximateTime<sensor_msgs::Image, opt_msgs::TrackArray> MySyncPolicy;

	message_filters::Synchronizer<MySyncPolicy> sync(MySyncPolicy(10), sub_image_, sub_tracks_);
	//sync.registerCallback(boost::bind(&callbackNoFeat, _1, _2));

	//pub = n.advertise<sensor_msgs::Image>("image_get/following",30);
	pub = n.advertise<opt_msgs::Track>("image_get/track_target",30);



	message_filters::Subscriber<sensor_msgs::Image> sub_image2_(n, "/HaarDispAdaColorImage", 3);
	message_filters::Subscriber<opt_msgs::TrackArray> sub_tracks2_(n, "/tracker/tracks_smoothed", 3);
	message_filters::Subscriber<opt_msgs::DetectionArray> sub_detect2_(n, "/detector/detections", 3);

	typedef message_filters::sync_policies::ApproximateTime<sensor_msgs::Image, opt_msgs::TrackArray, opt_msgs::DetectionArray> MySyncPolicy2;

	message_filters::Synchronizer<MySyncPolicy2> sync2(MySyncPolicy2(10), sub_image2_, sub_tracks2_, sub_detect2_);
	sync2.registerCallback(boost::bind(&callbackNoFeatCarac, _1, _2, _3));

	pub_str = n.advertise<std_msgs::String>("image_get/string",30);
	
	ROS_INFO("Following listo");

	ros::spin();

	//cv::destroyWindow("Following");


  return 0;
}
